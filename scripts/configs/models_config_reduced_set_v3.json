{
    "dino-vit-base-p16": {
        "model_name": "dino-vit-base-p16",
        "source": "ssl",
        "model_parameters": {
            "extract_cls_token": true,
            "token_extraction": "cls_token"
        },
        "module_name": "norm",
        "objective": "Self-Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 768,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 85798656,
        "size_fmt": "85.8M",
        "size_class": "small"
    },
    "mae-vit-base-p16": {
        "model_name": "mae-vit-base-p16",
        "source": "ssl",
        "model_parameters": {
            "extract_cls_token": true,
            "token_extraction": "cls_token"
        },
        "module_name": "norm",
        "objective": "Self-Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 768,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 86388480,
        "size_fmt": "86.4M",
        "size_class": "small"
    },
    "OpenCLIP_RN50_openai": {
        "model_name": "OpenCLIP",
        "source": "custom",
        "model_parameters": {
            "variant": "RN50",
            "dataset": "openai"
        },
        "module_name": "visual",
        "objective": "Image-Text",
        "dataset": "WIT-400M",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 1024,
        "alignment": null,
        "dataset_class": "Large",
        "size": 102007137,
        "size_fmt": "102.0M",
        "size_class": "medium"
    },
    "OpenCLIP_ViT-B-16_openai": {
        "model_name": "OpenCLIP",
        "source": "custom",
        "model_parameters": {
            "variant": "ViT-B-16",
            "dataset": "openai"
        },
        "module_name": "visual",
        "objective": "Image-Text",
        "dataset": "WIT-400M",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 512,
        "alignment": null,
        "dataset_class": "Large",
        "size": 149620737,
        "size_fmt": "149.6M",
        "size_class": "medium"
    },
    "resnet50": {
        "model_name": "resnet50",
        "source": "torchvision",
        "model_parameters": {
            "weights": "DEFAULT"
        },
        "module_name": "avgpool",
        "objective": "Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 2048,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 25557032,
        "size_fmt": "25.6M",
        "size_class": "small"
    },
    "resnet152": {
        "model_name": "resnet152",
        "source": "torchvision",
        "model_parameters": {
            "weights": "DEFAULT"
        },
        "module_name": "avgpool",
        "objective": "Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 2048,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 60192808,
        "size_fmt": "60.2M",
        "size_class": "small"
    },
    "dino-vit-base-p16TEST": {
        "model_name": "dino-vit-base-p16TEST",
        "source": "ssl",
        "model_parameters": {
            "extract_cls_token": true,
            "token_extraction": "cls_token"
        },
        "module_name": "norm",
        "objective": "Self-Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 768,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 85798656,
        "size_fmt": "85.8M",
        "size_class": "small"
    },
    "mae-vit-base-p16TEST": {
        "model_name": "mae-vit-base-p16TEST",
        "source": "ssl",
        "model_parameters": {
            "extract_cls_token": true,
            "token_extraction": "cls_token"
        },
        "module_name": "norm",
        "objective": "Self-Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 768,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 86388480,
        "size_fmt": "86.4M",
        "size_class": "small"
    },
    "OpenCLIP_RN50_openaiTEST": {
        "model_name": "OpenCLIPTEST",
        "source": "custom",
        "model_parameters": {
            "variant": "RN50",
            "dataset": "openai"
        },
        "module_name": "visual",
        "objective": "Image-Text",
        "dataset": "WIT-400M",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 1024,
        "alignment": null,
        "dataset_class": "Large",
        "size": 102007137,
        "size_fmt": "102.0M",
        "size_class": "medium"
    },
    "OpenCLIP_ViT-B-16_openaiTEST": {
        "model_name": "OpenCLIPTEST",
        "source": "custom",
        "model_parameters": {
            "variant": "ViT-B-16",
            "dataset": "openai"
        },
        "module_name": "visual",
        "objective": "Image-Text",
        "dataset": "WIT-400M",
        "architecture_class": "Transformer",
        "architecture": "ViT",
        "embedding_dim": 512,
        "alignment": null,
        "dataset_class": "Large",
        "size": 149620737,
        "size_fmt": "149.6M",
        "size_class": "medium"
    },
    "resnet50TEST": {
        "model_name": "resnet50TEST",
        "source": "torchvision",
        "model_parameters": {
            "weights": "DEFAULT"
        },
        "module_name": "avgpool",
        "objective": "Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 2048,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 25557032,
        "size_fmt": "25.6M",
        "size_class": "small"
    },
    "resnet152TEST": {
        "model_name": "resnet152TEST",
        "source": "torchvision",
        "model_parameters": {
            "weights": "DEFAULT"
        },
        "module_name": "avgpool",
        "objective": "Supervised",
        "dataset": "ImageNet1k",
        "architecture_class": "Convolutional",
        "architecture": "ResNet",
        "embedding_dim": 2048,
        "alignment": null,
        "dataset_class": "ImageNet1k",
        "size": 60192808,
        "size_fmt": "60.2M",
        "size_class": "small"
    }
}