{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook 4.6: *Do dataset categories influence relative similarity consistency?*\n",
    "\n",
    "This notebook creates figures for section 4.6. We visualize correlation coefficients between all dataset pairs, both grouped by training objectives and without grouping. This provides a comprehensive view of consistency patterns across different dataset categories.\n"
   ],
   "id": "968ebba7574575d5"
  },
  {
   "cell_type": "code",
   "id": "3803fca6-5068-4b1c-900e-58e1afce3a68",
   "metadata": {},
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from constants import cat_name_mapping, BASE_PATH_RESULTS\n",
    "from helper import save_or_show, pp_storing_path, load_all_datasetnames_n_info\n",
    "\n",
    "sys.path.append('..')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Global variables and data loading",
   "id": "79935ce323351c2c"
  },
  {
   "cell_type": "code",
   "id": "bbea6ec7-0895-4896-a25a-c686022cbf3e",
   "metadata": {},
   "source": [
    "# Load dataset information\n",
    "ds_list, ds_info = load_all_datasetnames_n_info('../scripts/webdatasets_w_insub10k.txt', verbose=True)\n",
    "\n",
    "## Storing information \n",
    "corr_method = 'spearmanr'  # spearmanr, pearsonr\n",
    "SAVE = False\n",
    "storing_path = pp_storing_path(BASE_PATH_RESULTS / f'plots/dist_r_coeff_dataset_cats_v2/{corr_method}', SAVE)\n",
    "\n",
    "## Load data\n",
    "orig_sim_data = BASE_PATH_RESULTS / f'aggregated/model_sims/all_metric_ds_model_pair_similarity.csv'\n",
    "assert orig_sim_data.exists(), f\"Path does not exist: {orig_sim_data}. Aggregated similarity data not found, please run aggregate_similarities_across_datasets.ipynb before.\"\n",
    "\n",
    "## Process Objective column\n",
    "orig_sim_data['Objective pair'] = orig_sim_data['Objective pair'].apply(eval)\n",
    "\n",
    "combinations_objectives = [('all', 'all'),\n",
    "                           ('Self-Supervised', 'Self-Supervised'),\n",
    "                           ('Image-Text', 'Supervised'), ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Helper funtions",
   "id": "d15407de8f60b96b"
  },
  {
   "cell_type": "code",
   "id": "f73971aa-587b-4ab5-ac1f-78bdae993ffe",
   "metadata": {},
   "source": [
    "def filter_data(mcat1, mcat2, sim_data, curr_suffix):\n",
    "    if len(mcat1) > 0 and len(mcat2) > 0:\n",
    "        sim_data_flat = sim_data[sim_data['Objective pair'].apply(lambda x: sorted(x) == sorted([mcat1, mcat2]))].copy()\n",
    "        curr_suffix = f\"_{cat_name_mapping[mcat1]}_{cat_name_mapping[mcat2]}\" + curr_suffix\n",
    "    else:\n",
    "        sim_data_flat = sim_data\n",
    "    return sim_data_flat, curr_suffix\n",
    "\n",
    "\n",
    "def get_ds_combs(df):\n",
    "    n_ds = df['DS'].nunique()\n",
    "    available_ds = sorted(list(set(df['DS'].unique()).intersection(ds_list)))\n",
    "    available_domains = sorted(ds_info['domain'].unique().tolist())\n",
    "    # available_ds = sorted(available_ds, key = lambda x: available_domains.index(ds_info.loc[x, 'domain']))\n",
    "    available_ds = sorted(available_ds, key=lambda x: (ds_info.loc[x, 'domain'], ds_info.loc[x, 'name']))\n",
    "    combs_DS = list(combinations(available_ds, 2))\n",
    "    corr_mat = pd.DataFrame(index=available_ds, columns=available_ds).astype('float')\n",
    "    return available_ds, available_domains, combs_DS, corr_mat\n",
    "\n",
    "\n",
    "def get_r_coeff(x, y, method='pearsonr'):\n",
    "    if method == 'pearsonr':\n",
    "        corr, _ = pearsonr(x, y)\n",
    "    elif method == 'spearmanr':\n",
    "        corr, _ = spearmanr(x, y)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_two_ds_data(ds1, ds2, all_sims):\n",
    "    data_2_ds = all_sims[all_sims['DS'].isin([ds1, ds2])].copy()\n",
    "    data_2_ds['model_pair'] = data_2_ds['Model 1'] + \", \" + data_2_ds['Model 2']\n",
    "    ds_similarities = pd.pivot_table(\n",
    "        data_2_ds,\n",
    "        columns='DS',\n",
    "        index='model_pair',\n",
    "        values='Similarity value',\n",
    "    )\n",
    "    return ds_similarities\n",
    "\n",
    "\n",
    "def fill_corr_mat(df, combs_DS, corr_mat):\n",
    "    for ds1, ds2 in combs_DS:\n",
    "        ds_sims = get_two_ds_data(ds1, ds2, df)\n",
    "        corr = get_r_coeff(ds_sims.values[:, 0], ds_sims.values[:, 1], method=corr_method)\n",
    "        corr_mat.loc[ds1, ds2] = float(corr)\n",
    "        corr_mat.loc[ds2, ds1] = float(corr)\n",
    "\n",
    "    np.fill_diagonal(corr_mat.values, 1)\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "def rename_idx_cols(corr_mat, available_ds):\n",
    "    new_naming = [ds_info.loc[ds, 'name'] for ds in available_ds]\n",
    "    corr_mat.index = new_naming\n",
    "    corr_mat.columns = new_naming\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "def get_all_correlations(df, corr_type, col_data):\n",
    "    r_vals = []\n",
    "    for ds1, ds2 in combinations(ds_list, 2):\n",
    "        ds1_subset = df[df['DS'] == ds1]\n",
    "        ds2_subset = df[df['DS'] == ds2]\n",
    "        r_vals.append({\n",
    "            'ds1': ds1,\n",
    "            'ds2': ds2,\n",
    "            'r coeff': get_r_coeff(ds1_subset[col_data].values, ds2_subset[col_data].values, corr_type)\n",
    "\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(r_vals)\n",
    "\n",
    "\n",
    "def get_all_ds_corr_mat(sim_metric):\n",
    "    all_sim_data = pd.read_csv(\n",
    "        Path('/home/space/diverse_priors/results/aggregated/model_sims/all_metric_ds_model_pair_similarity.csv'))\n",
    "    all_sim_data = all_sim_data[all_sim_data['DS'].isin(ds_list)]\n",
    "    sim_data = all_sim_data[all_sim_data['Similarity metric'] == sim_metric]\n",
    "    r_corrs = get_all_correlations(sim_data, corr_method, 'Similarity value')\n",
    "    corr_mat = pd.DataFrame(columns=ds_list, index=ds_list, dtype=float)\n",
    "\n",
    "    def add_entries(row):\n",
    "        corr_mat.loc[row['ds1'], row['ds2']] = row['r coeff']\n",
    "        corr_mat.loc[row['ds2'], row['ds1']] = row['r coeff']\n",
    "\n",
    "    r_corrs.apply(add_entries, axis=1)\n",
    "    np.fill_diagonal(corr_mat.values, 1)\n",
    "    new_index = ds_info.loc[corr_mat.index, :].sort_values(['domain', 'name']).index\n",
    "    corr_mat = corr_mat.loc[new_index, new_index]\n",
    "    corr_mat.index = ds_info.loc[corr_mat.index, 'name']\n",
    "    corr_mat.columns = ds_info.loc[corr_mat.columns, 'name']\n",
    "    return corr_mat, list(new_index), sorted(ds_info.loc[new_index, 'domain'].unique())\n",
    "\n",
    "\n",
    "def plot_heatmap_v2(ax, corr_mat, available_ds, available_domains, vmin=-0.44, vmax=1):\n",
    "    sns.heatmap(corr_mat, square=True, cmap='mako', cbar=False, vmin=vmin, vmax=vmax, ax=ax)\n",
    "\n",
    "    tmp = np.where(\n",
    "        ~(ds_info.loc[available_ds, 'domain'].iloc[:-1].values == ds_info.loc[available_ds, 'domain'].iloc[1:].values))[\n",
    "        0]\n",
    "    tmp += 1\n",
    "\n",
    "    for val in tmp:\n",
    "        ax.axhline(val, c='black', ls=\":\")\n",
    "        ax.axvline(val, c='black', ls=\":\")\n",
    "\n",
    "    ax.text(5, -1.5, '\\n'.join(available_domains[0].split(' ')), ha='center', va='top', fontsize=10, color='black')\n",
    "    ax.text(13, -1.5, '\\n'.join(available_domains[1].split(' ')), ha='center', va='top', fontsize=10, color='black')\n",
    "    ax.text(17.75, -1, available_domains[2], ha='center', va='top', fontsize=10, color='black')\n",
    "    ax.text(21.75, -1, available_domains[3], ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def setup_figure(m, size_fig=7, size_bar=0.25, wspace=0.05):\n",
    "    fig = plt.figure(figsize=(m * size_fig + size_bar, size_fig))\n",
    "    gs = GridSpec(1, m + 1, width_ratios=[size_fig] * m + [size_bar], wspace=wspace)\n",
    "\n",
    "    # Create axes with shared x and y\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    axs = [ax0] + [fig.add_subplot(gs[0, i], sharey=ax0, sharex=ax0) for i in range(1, m)]\n",
    "    return fig, gs, axs\n",
    "\n",
    "\n",
    "def add_colorbar(gs, cmap='mako', vmin=-0.44, vmax=1):\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm.set_array([])\n",
    "    cax = fig.add_subplot(gs[0, -1])\n",
    "    plt.colorbar(sm, cax=cax)\n",
    "\n",
    "\n",
    "def update_suffix(suffix, mcat1, mcat2):\n",
    "    def pp_str(x):\n",
    "        return x.lower().replace(' ', '_')\n",
    "\n",
    "    if mcat1 == mcat2:\n",
    "        suffix += f\"_2_{pp_str(mcat1)}\"\n",
    "    else:\n",
    "        suffix += f\"_{pp_str(mcat1)}_n_{pp_str(mcat2)}\"\n",
    "    return suffix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compute consistency matrices computed on different subsets of model pairs representational similarities ",
   "id": "39ac0bfa780f8a65"
  },
  {
   "cell_type": "code",
   "id": "1b160e5d-9333-45cf-93fe-001b54ded612",
   "metadata": {},
   "source": [
    "m = len(combinations_objectives)\n",
    "\n",
    "for sim_metric in ['CKA RBF 0.4', 'CKA linear']:\n",
    "    print(sim_metric)\n",
    "\n",
    "    sim_data = orig_sim_data[orig_sim_data['Similarity metric'] == sim_metric].reset_index().copy()\n",
    "\n",
    "    suffix = \"_\" + sim_metric.replace(\" \", \"_\").lower()\n",
    "\n",
    "    fig, gs, axs = setup_figure(m, size_fig=6.5, size_bar=0.25, wspace=0.05)\n",
    "\n",
    "    for i, (mcat1, mcat2) in enumerate(combinations_objectives):\n",
    "        ax = axs[i]\n",
    "        if mcat1 == 'all' and mcat2 == 'all':\n",
    "            corr_mat, available_ds, available_domains = get_all_ds_corr_mat(sim_metric)\n",
    "        else:\n",
    "            sim_data_flat, _ = filter_data(mcat1, mcat2, sim_data, suffix)\n",
    "            available_ds, available_domains, combs_DS, corr_mat = get_ds_combs(sim_data_flat)\n",
    "            corr_mat = fill_corr_mat(sim_data_flat, combs_DS, corr_mat)\n",
    "            corr_mat = rename_idx_cols(corr_mat, available_ds)\n",
    "\n",
    "        plot_heatmap_v2(ax, corr_mat, available_ds, available_domains)\n",
    "\n",
    "        if i > 0:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "        suffix = update_suffix(suffix, mcat1, mcat2)\n",
    "\n",
    "    add_colorbar(gs, cmap='mako', vmin=-0.44, vmax=1)\n",
    "\n",
    "    save_or_show(plt.gcf(), storing_path / f'grouped_heatmap{suffix}.pdf', SAVE)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
