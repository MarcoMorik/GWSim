{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c1c5368b6f12fd",
   "metadata": {},
   "source": [
    "## Notebook appendix F: *Distribution correlation coefficients downstream task performance vs. model similarity*\n",
    "This notebook creates the plots for section F in the appendix. It shows the correlations between the downstream task performance differences and the model similarities for each dataset category and dataset. The correlations are calculated using the Pearson correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f88e1e-0ced-4d1e-8684-e5c6c3560294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from constants import exclude_models, exclude_models_w_mae, cat_name_mapping, model_config_file, \\\n",
    "    BASE_PATH_RESULTS, ds_list_perf_file, fontsizes, fontsizes_cols\n",
    "from helper import load_model_configs_and_allowed_models, save_or_show, load_all_datasetnames_n_info, \\\n",
    "    pp_storing_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c7d53-9388-462f-aea4-1481454938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config datasets\n",
    "ds_list_perf, ds_info = load_all_datasetnames_n_info(ds_list_perf_file, verbose=False)\n",
    "\n",
    "### Config similarity data\n",
    "sim_data_path = BASE_PATH_RESULTS / 'aggregated' / 'model_sims/all_metric_ds_model_pair_similarity.csv'\n",
    "assert sim_data_path.exists(), f\"Path does not exist: {sim_data_path}. Aggregated similarity data not found, please run `aggregate_similarities_across_datasets.ipynb` before.\"\n",
    "\n",
    "### Config performance data\n",
    "perf_data_path = BASE_PATH_RESULTS / f'aggregated/single_model_performance/all_ds.csv'\n",
    "assert perf_data_path.exists(), f\"Path does not exist: {perf_data_path}. Aggregated performance data not found, please run `aggregate_downstream_task_perfs.ipynb` before.\"\n",
    "\n",
    "### Config datasets to include\n",
    "ds_to_include = set(ds_list_perf) - set(['cifar100-coarse', 'entity13'])\n",
    "ds_to_include.add('imagenet-subset-10k')\n",
    "remaining_ds = sorted(list(set(ds_list_perf) - set(ds_to_include)))\n",
    "\n",
    "## Storing information\n",
    "suffix = ''\n",
    "# suffix = '_ wo_mae'\n",
    "\n",
    "## Version and plotting info\n",
    "version = 'arxiv'\n",
    "curr_fontsizes = fontsizes if version == 'arxiv' else fontsizes_cols\n",
    "\n",
    "SAVE = True\n",
    "storing_path = pp_storing_path(BASE_PATH_RESULTS / 'plots' / 'final' / version / 'app_F_corr_perf_vs_sim', SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6095ad82d1eca1",
   "metadata": {},
   "source": [
    "#### Load the model configurations and allowed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a906935-71d2-4ed4-955b-424e2f7c8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_excl_models = exclude_models_w_mae if 'mae' in suffix else exclude_models\n",
    "\n",
    "model_configs, allowed_models = load_model_configs_and_allowed_models(\n",
    "    path=model_config_file,\n",
    "    exclude_models=curr_excl_models,\n",
    "    exclude_alignment=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f63fd722120cce",
   "metadata": {},
   "source": [
    "#### Load similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6713b21cb6dfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pd.read_csv(sim_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4109a6-f2e8-4357-94c6-9fdfda095f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter similarity data only for desired datasets\n",
    "print(sim_data.shape)\n",
    "if ds_to_include:\n",
    "    sim_data = sim_data[sim_data['DS'].isin(ds_to_include)].reset_index(drop=True)\n",
    "print(sim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e4ea7207b2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename datasets with info\n",
    "sim_data['DS category'] = sim_data['DS'].apply(lambda x: ds_info.loc[x, 'domain'])\n",
    "sim_data['DS'] = sim_data['DS'].apply(lambda x: ds_info.loc[x, 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa022cd-d2a2-49e3-b32f-ba830e73caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post-process 'pair' columns\n",
    "def pp_pair_col(df_col):\n",
    "    return df_col.apply(eval).apply(lambda x: f\"{cat_name_mapping[x[0]]}, {cat_name_mapping[x[1]]}\")\n",
    "\n",
    "\n",
    "pair_columns = [col for col in sim_data.columns if 'pair' in col]\n",
    "sim_data[pair_columns] = sim_data[pair_columns].apply(pp_pair_col, axis=0)\n",
    "pair_columns += [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb4868cec85324",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter only for allowed models\n",
    "sim_data = sim_data[sim_data['Model 1'].isin(allowed_models) & sim_data['Model 2'].isin(allowed_models)].reset_index(\n",
    "    drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00674a23950edb",
   "metadata": {},
   "source": [
    "#### Load performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea041adb-439f-41f2-bf7d-e6c6b7002ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_res = pd.read_csv(perf_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442331298e1b7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds_to_include:\n",
    "    perf_res = perf_res[perf_res['DS'].isin(ds_to_include)].reset_index(drop=True)\n",
    "perf_res['DS category'] = perf_res['DS'].apply(lambda x: ds_info.loc[x, 'domain'])\n",
    "perf_res['DS'] = perf_res['DS'].apply(lambda x: ds_info.loc[x, 'name'])\n",
    "perf_res = perf_res[perf_res['Model'].isin(allowed_models)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bc00b-d869-400e-9f01-bdbd7204125b",
   "metadata": {},
   "source": [
    "#### Combine model similarities and performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588a9f-92df-4445-bcb1-bb8de121d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_perf(row):\n",
    "    m1_perf = perf_res.loc[(perf_res['Model'] == row['Model 1']) & (perf_res['DS'] == row['DS']), 'TestAcc'].item()\n",
    "    m2_perf = perf_res.loc[(perf_res['Model'] == row['Model 2']) & (perf_res['DS'] == row['DS']), 'TestAcc'].item()\n",
    "    return m1_perf, m2_perf, np.abs(m1_perf - m2_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fb4e6-5465-4286-9c86-b970694da0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_per_pair = pd.DataFrame(sim_data.apply(get_model_perf, axis=1).tolist(),\n",
    "                                    columns=['Model 1 perf.', 'Model 2 perf.', 'abs. diff. perf.']).reset_index(\n",
    "    drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05604c7-52f7-4cf1-87cc-51a10ab4fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_new = pd.concat([sim_data, performance_per_pair], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafaa1d-2b2d-41a0-8f2c-05d4db6c7016",
   "metadata": {},
   "source": [
    "#### Compute the correlations between the performance gaps and the model similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8822f47a78afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(subset_data):\n",
    "    corr_sp, _ = spearmanr(subset_data['Similarity value'], subset_data['abs. diff. perf.'])\n",
    "    corr_pr, _ = pearsonr(subset_data['Similarity value'], subset_data['abs. diff. perf.'])\n",
    "    return {'spearmanr': corr_sp, 'pearsonr': corr_pr}\n",
    "\n",
    "\n",
    "r_coeffs = sim_data_new.groupby(['Similarity metric', 'DS'])[['Similarity value', 'abs. diff. perf.']].apply(\n",
    "    get_correlation)\n",
    "r_coeffs = pd.DataFrame(r_coeffs.tolist(), index=r_coeffs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476f9f1a24c51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_coeffs_tmp = r_coeffs.reset_index()\n",
    "r_coeffs_tmp['name'] = r_coeffs_tmp['DS']\n",
    "tmp = pd.merge(r_coeffs_tmp, ds_info.reset_index(names=['DS']), how='left', on='name')\n",
    "tmp = tmp.drop(columns=['DS_y'])\n",
    "tmp = tmp[~tmp.duplicated()].reset_index(drop=True)\n",
    "tmp = tmp.sort_values(['Similarity metric', 'domain', 'spearmanr']).reset_index(drop=True)\n",
    "if SAVE:\n",
    "    fn = storing_path / 'corr_perf_vs_sim_per_ds.csv'\n",
    "    tmp.to_csv(fn, index=False)\n",
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade499e-c021-4ea7-a1f0-224d4131a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_ds_perf_sim_corr = pd.melt(\n",
    "    tmp,\n",
    "    id_vars=['Similarity metric', 'DS_x', 'name', 'domain'],\n",
    "    var_name='Correlation metric',\n",
    "    value_name='Correlation coefficient'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636564c-c9f6-4f60-833c-307c1c4b1245",
   "metadata": {},
   "source": [
    "### Plot the barplots (i.e., correlation distributions) for each dataset category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1661a-af2d-4345-8a95-ebe2fd01e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_colors = {\n",
    "    'Natural (multi-domain)': '#8da0cb',\n",
    "    'Natural (single-domain)': '#e78ac3',\n",
    "    'Specialized': '#a6d854',\n",
    "    'Structured': '#b3b3b3'\n",
    "}\n",
    "\n",
    "df = melted_ds_perf_sim_corr[\n",
    "    (melted_ds_perf_sim_corr['Similarity metric'] == 'CKA linear') &\n",
    "    (melted_ds_perf_sim_corr['Correlation metric'] == 'pearsonr')\n",
    "]\n",
    "\n",
    "if version == 'arxiv':\n",
    "    bbox_to_anchor=(0.19, 1.02)\n",
    "    fontsize_legend = curr_fontsizes['label']\n",
    "    figsize=(8, 5)\n",
    "else:\n",
    "    bbox_to_anchor = (0.21, 1.02)\n",
    "    fontsize_legend = curr_fontsizes['ticks']\n",
    "    figsize=(9, 6)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "unique_names = df['name'].unique()\n",
    "x = np.arange(len(unique_names))\n",
    "\n",
    "colors = [domain_colors[domain] for domain in df['domain']]\n",
    "plt.scatter(x, df['Correlation coefficient'], \n",
    "           c=colors, \n",
    "           s=100,  \n",
    "           alpha=1) \n",
    "\n",
    "\n",
    "plt.ylabel('Correlation Coefficient', fontsize=curr_fontsizes['label'])\n",
    "plt.xticks(x, unique_names, rotation=45, ha='right')\n",
    "plt.tick_params('both', labelsize=curr_fontsizes['ticks'])\n",
    "\n",
    "plt.axhline(-.3, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "plt.axhline(-.5, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "plt.axhline(-.7, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "\n",
    "domain_patches = [plt.scatter([], [], c=color, label=domain, s=100)\n",
    "                 for domain, color in domain_colors.items()]\n",
    "\n",
    "plt.legend(handles=domain_patches, \n",
    "          loc='upper center', \n",
    "          bbox_to_anchor=bbox_to_anchor, \n",
    "          title='',\n",
    "          frameon=False,\n",
    "          fontsize=fontsize_legend,\n",
    "          ncol=1,\n",
    "          )\n",
    "\n",
    "plt.tight_layout()\n",
    "save_or_show(plt.gcf(), storing_path / f'scatter_corr_perf_vs_sim_per_ds_cat_cka_linear.pdf', SAVE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
