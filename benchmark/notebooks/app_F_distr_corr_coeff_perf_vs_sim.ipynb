{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f88e1e-0ced-4d1e-8684-e5c6c3560294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from itertools import product\n",
    "import textwrap\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from constants import exclude_models, exclude_models_w_mae, cat_name_mapping, ds_info_file, model_config_file, fontsizes\n",
    "from helper import load_model_configs_and_allowed_models, save_or_show, load_ds_info\n",
    "\n",
    "sys.path.append('..')\n",
    "from scripts.helper import parse_datasets\n",
    "\n",
    "from clip_benchmark.analysis.utils import retrieve_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9c7d53-9388-462f-aea4-1481454938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_aggregated = Path('/home/space/diverse_priors/results/aggregated')\n",
    "\n",
    "### Config similarity data\n",
    "sim_data = pd.read_csv(base_path_aggregated / 'model_sims/all_metric_ds_model_pair_similarity.csv')\n",
    "\n",
    "### Config performance data\n",
    "ds_list_perf = parse_datasets('../scripts/webdatasets_w_in1k.txt')\n",
    "ds_list_perf = list(map(lambda x: x.replace('/', '_'), ds_list_perf))\n",
    "\n",
    "ds_info = load_ds_info(ds_info_file)\n",
    "\n",
    "results_root = '/home/space/diverse_priors/results/linear_probe/single_model'\n",
    "\n",
    "### Config datasets to include\n",
    "ds_to_include= set(ds_list_perf) - set(['cifar100-coarse', 'entity13']) \n",
    "ds_to_include.add('imagenet-subset-10k')\n",
    "remaining_ds = sorted(list(set(ds_list_perf) - set(ds_to_include)))\n",
    "\n",
    "## Storing information\n",
    "suffix = ''\n",
    "# suffix = '_ wo_mae'\n",
    "\n",
    "SAVE = True\n",
    "storing_path = Path(f'/home/space/diverse_priors/results/plots/scatter_sim_vs_performance_v2')\n",
    "if SAVE:\n",
    "    storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4109a6-f2e8-4357-94c6-9fdfda095f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100800, 9)\n",
      "(92736, 9)\n"
     ]
    }
   ],
   "source": [
    "## Filter similarity data only for desired datasets\n",
    "print(sim_data.shape)\n",
    "if ds_to_include:\n",
    "    sim_data = sim_data[sim_data['DS'].isin(ds_to_include)].reset_index(drop=True)\n",
    "print(sim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86e4ea7207b2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename datasets with info\n",
    "sim_data['DS category'] = sim_data['DS'].apply(lambda x: ds_info.loc[x, 'domain'])\n",
    "sim_data['DS'] = sim_data['DS'].apply(lambda x: ds_info.loc[x, 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa022cd-d2a2-49e3-b32f-ba830e73caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post-process 'pair' columns\n",
    "def pp_pair_col(df_col):\n",
    "    return df_col.apply(eval).apply(lambda x: f\"{cat_name_mapping[x[0]]}, {cat_name_mapping[x[1]]}\")\n",
    "\n",
    "\n",
    "pair_columns = [col for col in sim_data.columns if 'pair' in col]\n",
    "sim_data[pair_columns] = sim_data[pair_columns].apply(pp_pair_col, axis=0)\n",
    "pair_columns += [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a906935-71d2-4ed4-955b-424e2f7c8fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. models original=64\n"
     ]
    }
   ],
   "source": [
    "curr_excl_models = exclude_models_w_mae if 'mae' in suffix else exclude_models\n",
    "\n",
    "model_configs, allowed_models = load_model_configs_and_allowed_models(\n",
    "    path=model_config_file,\n",
    "    exclude_models=curr_excl_models,\n",
    "    exclude_alignment=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbb4868cec85324",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter only for allowed models\n",
    "sim_data = sim_data[sim_data['Model 1'].isin(allowed_models) & sim_data['Model 2'].isin(allowed_models)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae860b3f-bea0-4082-b244-ea22e73dd464",
   "metadata": {},
   "source": [
    "#### Retrieve the downstream task performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cc003f-9ecd-417b-96fd-6ef8df216e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# # Ignore UserWarnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# res = []\n",
    "# for ds, mid in product(ds_list_perf, allowed_models):\n",
    "#     performance = retrieve_performance(\n",
    "#         model_id=mid, \n",
    "#         dataset_id=ds, \n",
    "#         metric_column='test_lp_acc1',\n",
    "#         results_root='/home/space/diverse_priors/results/linear_probe/single_model',\n",
    "#         regularization=\"weight_decay\",\n",
    "#         allow_db_results=False\n",
    "#     )\n",
    "#     res.append({\n",
    "#         'DS': ds,\n",
    "#         'Model': mid,\n",
    "#         'TestAcc': performance\n",
    "#     })\n",
    "# perf_res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e3e893-a2dd-46b0-9c7d-1dd195cf2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_res.to_csv(base_path_aggregated/ f'single_model_performance/all_ds{suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea041adb-439f-41f2-bf7d-e6c6b7002ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_res = pd.read_csv(base_path_aggregated / f'single_model_performance/all_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442331298e1b7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds_to_include:\n",
    "    perf_res = perf_res[perf_res['DS'].isin(ds_to_include)].reset_index(drop=True)\n",
    "perf_res['DS category'] = perf_res['DS'].apply(lambda x: ds_info.loc[x, 'domain'])\n",
    "perf_res['DS'] = perf_res['DS'].apply(lambda x: ds_info.loc[x, 'name'])\n",
    "perf_res = perf_res[perf_res['Model'].isin(allowed_models)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bc00b-d869-400e-9f01-bdbd7204125b",
   "metadata": {},
   "source": [
    "#### Combine model similarities and performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a588a9f-92df-4445-bcb1-bb8de121d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_perf(row):\n",
    "    m1_perf = perf_res.loc[(perf_res['Model'] == row['Model 1']) & (perf_res['DS'] == row['DS']), 'TestAcc'].item()\n",
    "    m2_perf = perf_res.loc[(perf_res['Model'] == row['Model 2']) & (perf_res['DS'] == row['DS']), 'TestAcc'].item()\n",
    "    return m1_perf, m2_perf, np.abs(m1_perf - m2_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23fb4e6-5465-4286-9c86-b970694da0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_per_pair = pd.DataFrame(sim_data.apply(get_model_perf, axis=1).tolist(),\n",
    "                                    columns=['Model 1 perf.', 'Model 2 perf.', 'abs. diff. perf.']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e05604c7-52f7-4cf1-87cc-51a10ab4fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_new = pd.concat([sim_data, performance_per_pair], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafaa1d-2b2d-41a0-8f2c-05d4db6c7016",
   "metadata": {},
   "source": [
    "#### Compute the correlations between the performance gaps and the model similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a8822f47a78afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(subset_data):\n",
    "    corr_sp, _ = spearmanr(subset_data['Similarity value'], subset_data['abs. diff. perf.'])\n",
    "    corr_pr, _ = pearsonr(subset_data['Similarity value'], subset_data['abs. diff. perf.'])\n",
    "    return {'spearmanr': corr_sp, 'pearsonr': corr_pr}\n",
    "\n",
    "\n",
    "r_coeffs = sim_data_new.groupby(['Similarity metric', 'DS'])[['Similarity value', 'abs. diff. perf.']].apply(\n",
    "    get_correlation)\n",
    "r_coeffs = pd.DataFrame(r_coeffs.tolist(), index=r_coeffs.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0232b-77c0-453b-a1bb-b0c1942d1d70",
   "metadata": {},
   "source": [
    "#### Plot the swarmplots (i.e., correlation distributions) for each dataset category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1476f9f1a24c51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_coeffs_tmp = r_coeffs.reset_index()\n",
    "r_coeffs_tmp['name'] = r_coeffs_tmp['DS']\n",
    "tmp = pd.merge(r_coeffs_tmp, ds_info.reset_index(names=['DS']), how='left', on='name')\n",
    "tmp = tmp.drop(columns=['DS_y'])\n",
    "tmp = tmp[~tmp.duplicated()].reset_index(drop=True)\n",
    "tmp = tmp.sort_values(['Similarity metric', 'domain', 'spearmanr']).reset_index(drop=True)\n",
    "if SAVE: \n",
    "    fn = storing_path / 'corr_perf_vs_sim_per_ds.csv'\n",
    "    tmp.to_csv(fn, index=False)\n",
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ade499e-c021-4ea7-a1f0-224d4131a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_ds_perf_sim_corr = pd.melt(\n",
    "    tmp,\n",
    "    id_vars=['Similarity metric', 'DS_x', 'name', 'domain'],\n",
    "    var_name='Correlation metric',\n",
    "    value_name='Correlation coefficient'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "630869a0-592c-406b-bbb8-81243a6d9385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1562606/1492667431.py:6: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(labels, ha='center')\n",
      "/tmp/ipykernel_1562606/1492667431.py:6: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(labels, ha='center')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored img at /home/space/diverse_priors/results/plots/scatter_sim_vs_performance_v2/swarm_corr_perf_vs_sim_per_ds_cat.pdf.\n"
     ]
    }
   ],
   "source": [
    "def wrap_labels(ax, width=10, break_long_words=False):\n",
    "    labels = []\n",
    "    for label in ax.get_xticklabels():\n",
    "        text = label.get_text()\n",
    "        labels.append(textwrap.fill(text, width=width, break_long_words=break_long_words))\n",
    "    ax.set_xticklabels(labels, ha='center')\n",
    "\n",
    "# Create the plot\n",
    "g = sns.catplot(\n",
    "    melted_ds_perf_sim_corr,\n",
    "    x='domain',\n",
    "    y='Correlation coefficient',\n",
    "    col='Similarity metric',\n",
    "    hue='Correlation metric',\n",
    "    order=sorted(melted_ds_perf_sim_corr['domain'].unique()),\n",
    "    height=3,\n",
    "    aspect=1.1,\n",
    "    legend_out=True  # Ensure legend is outside\n",
    ")\n",
    "\n",
    "# Add horizontal line\n",
    "g.map(plt.axhline, y=-0.5, color='grey', linestyle='--')\n",
    "\n",
    "# Apply text wrapping to x-axis labels\n",
    "for ax in g.axes.flat:\n",
    "    wrap_labels(ax)\n",
    "\n",
    "# Set titles and labels\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.set_xlabels(\"\")\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "g.fig.subplots_adjust(wspace=0.1)  # Adjust bottom and right margins\n",
    "\n",
    "# Move the legend\n",
    "sns.move_legend(g, bbox_to_anchor=(1, 0.5), loc='lower left')\n",
    "\n",
    "save_or_show(g.fig, storing_path / f'swarm_corr_perf_vs_sim_per_ds_cat.pdf', SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636564c-c9f6-4f60-833c-307c1c4b1245",
   "metadata": {},
   "source": [
    "#### Plot the barplots (i.e., correlation distributions) for each dataset category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e24bc9c-adb9-4a32-82e0-1d744462bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored img at /home/space/diverse_priors/results/plots/scatter_sim_vs_performance_v2/bar_corr_perf_vs_sim_per_ds_cat_cka_linear.pdf.\n"
     ]
    }
   ],
   "source": [
    "domain_colors = {\n",
    "    'pearsonr':{\n",
    "        'Natural (multi-domain)': '#1f77b4',\n",
    "        'Natural (single-domain)': '#ff7f0e',\n",
    "        'Specialized': '#2ca02c',\n",
    "        'Structured': '#d62728'\n",
    "    },\n",
    "    'spearmanr':{\n",
    "        'Natural (multi-domain)': '#aec7e8',\n",
    "        'Natural (single-domain)': '#ffbb78',\n",
    "        'Specialized': '#98df8a',\n",
    "        'Structured': '#ff9896'\n",
    "    } \n",
    "}\n",
    "\n",
    "df = melted_ds_perf_sim_corr[(melted_ds_perf_sim_corr['Similarity metric'] == 'CKA linear')]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Calculate bar positions\n",
    "unique_names = df['name'].unique()\n",
    "x = np.arange(len(unique_names))\n",
    "width = 0.4\n",
    "\n",
    "# Plot bars for each metric\n",
    "for i, metric in enumerate(['pearsonr', 'spearmanr']):\n",
    "    mask = df['Correlation metric'] == metric\n",
    "    data = df[mask]\n",
    "    \n",
    "    # Create colors list\n",
    "    colors = [domain_colors[metric][domain] for domain in data['domain']]\n",
    "    \n",
    "    plt.bar(x[data['name'].isin(unique_names)] + (width if metric == 'spearmanr' else -width)/2,\n",
    "           data['Correlation coefficient'],\n",
    "           width,\n",
    "           label=metric,\n",
    "           color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "plt.xticks(x, unique_names, rotation=45, ha='right', fontsize=11)\n",
    "plt.tick_params('both', labelsize=11)\n",
    "plt.axhline(-.3, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "plt.axhline(-.5, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "plt.axhline(-.7, alpha=0.5, ls=':', c='grey', zorder=-1)\n",
    "\n",
    "# Create custom legend for domains and metrics\n",
    "domain_patches = [plt.Rectangle((0,0),1,1, fc=color, label=domain) \n",
    "                 for domain, color in domain_colors['pearsonr'].items()]\n",
    "metric_patches = [\n",
    "    plt.Rectangle((0,0),1,1, fc='gray', label='Pearson coefficient (Darker)'),\n",
    "    plt.Rectangle((0,0),1,1, fc='gray', alpha=0.7, label='Spearman coefficient (Lighter)')\n",
    "]\n",
    "# Add both legends\n",
    "plt.legend(handles=domain_patches + metric_patches, \n",
    "          loc='upper left',\n",
    "          bbox_to_anchor=(1, 1),\n",
    "          title='Domains and Metrics',\n",
    "          frameon=False,\n",
    "          fontsize=11,\n",
    "          title_fontsize=11)\n",
    "plt.tight_layout()\n",
    "save_or_show(plt.gcf(), storing_path / f'bar_corr_perf_vs_sim_per_ds_cat_cka_linear.pdf', SAVE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
