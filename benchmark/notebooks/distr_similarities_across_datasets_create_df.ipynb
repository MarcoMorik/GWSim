{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba95ca02-1f2b-45e3-b4d0-1a2b696c0248",
   "metadata": {},
   "source": [
    "## Aggregation model similarities across for different datasets and similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f76510c-3062-4c6f-9c36-88b1e9218635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from constants import exclude_models, model_config_file\n",
    "from helper import load_model_configs_and_allowed_models, load_similarity_matrices\n",
    "\n",
    "sys.path.append('..')\n",
    "from scripts.helper import parse_datasets\n",
    "from constants import sim_metric_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00493259-741a-491c-88fe-ab761d79c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wds_fer2013', 'wds_voc2007', 'wds_cars', 'wds_fgvc_aircraft', 'wds_stl10', 'wds_gtsrb', 'wds_country211', 'wds_vtab_caltech101', 'wds_vtab_cifar10', 'wds_vtab_cifar100', 'wds_vtab_diabetic_retinopathy', 'wds_vtab_dmlab', 'wds_vtab_dtd', 'wds_vtab_eurosat', 'wds_vtab_flowers', 'wds_vtab_pets', 'wds_vtab_pcam', 'wds_vtab_resisc45', 'wds_vtab_svhn', 'entity30', 'living17', 'nonliving26', 'imagenet-subset-10k']\n"
     ]
    }
   ],
   "source": [
    "base_path_similarity_matrices = Path('/home/space/diverse_priors/model_similarities')\n",
    "\n",
    "sim_metrics = [\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.4',\n",
    "    'cka_kernel_linear_unbiased',\n",
    "    'rsa_method_correlation_corr_method_spearman'\n",
    "]\n",
    "sim_metrics_mapped = [sim_metric_name_mapping[k] for k in sim_metrics]\n",
    "\n",
    "ds_list = parse_datasets('../scripts/webdatasets_w_insub10k.txt')\n",
    "ds_list = list(map(lambda x: x.replace('/', '_'), ds_list))\n",
    "print(ds_list)\n",
    "\n",
    "storing_path = Path('/home/space/diverse_priors/results/aggregated/model_sims')\n",
    "storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9fc269-7957-4bd0-a8e7-d73ee350a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. models original=64\n",
      "(64, 14)\n"
     ]
    }
   ],
   "source": [
    "model_configs, allowed_models = load_model_configs_and_allowed_models(\n",
    "    path=model_config_file,\n",
    "    exclude_models=exclude_models,\n",
    "    exclude_alignment=True,\n",
    ")\n",
    "print(model_configs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44eaa2e3-c8fe-47ba-937a-68d80d273ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mats = load_similarity_matrices(\n",
    "    path=base_path_similarity_matrices,\n",
    "    ds_list=ds_list,\n",
    "    sim_metrics=sim_metrics,\n",
    "    allowed_models=allowed_models,\n",
    ")\n",
    "sim_mats = {sim_metric_name_mapping[k]: v for k, v in sim_mats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a879d432-1159-4726-a8cb-1abdbb35d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sim_values(sim_mat):\n",
    "    iu2 = np.triu_indices(sim_mat.shape[0], k=1)\n",
    "    flat_sim_mat = pd.DataFrame({\n",
    "        'Model 1': sim_mat.index.values[iu2[0]],\n",
    "        'Model 2': sim_mat.columns.values[iu2[1]],\n",
    "        'Similarity value': sim_mat.values[iu2],\n",
    "    })\n",
    "    return flat_sim_mat\n",
    "\n",
    "\n",
    "def sort_tuple(tup):\n",
    "    return tuple(sorted(tup))\n",
    "\n",
    "\n",
    "def get_cat_pair(row, cat):\n",
    "    pair_info = (\n",
    "        model_configs.loc[row['Model 1'], cat],\n",
    "        model_configs.loc[row['Model 2'], cat]\n",
    "    )\n",
    "    return sort_tuple(pair_info)\n",
    "\n",
    "\n",
    "def process_sim_mat(sim_mat, metric, ds):\n",
    "    flat_sim_mat = flatten_sim_values(sim_mat)\n",
    "    flat_sim_mat['Similarity metric'] = metric\n",
    "    flat_sim_mat['DS'] = ds\n",
    "    flat_sim_mat['Objective pair'] = flat_sim_mat.apply(get_cat_pair, axis=1, cat='objective')\n",
    "    flat_sim_mat['Architecture pair'] = flat_sim_mat.apply(get_cat_pair, axis=1, cat='architecture_class')\n",
    "    flat_sim_mat['Dataset pair'] = flat_sim_mat.apply(get_cat_pair, axis=1, cat='dataset_class')\n",
    "    flat_sim_mat['Model size pair'] = flat_sim_mat.apply(get_cat_pair, axis=1, cat='size_class')\n",
    "    cols = flat_sim_mat.columns.tolist()\n",
    "    flat_sim_mat = flat_sim_mat[cols[3:5] + cols[:3] + cols[5:]]\n",
    "    return flat_sim_mat\n",
    "\n",
    "\n",
    "def get_similarity_dataframe(similarity_matrices):\n",
    "    dfs = []\n",
    "    for sim_metric, sim_mats_w_metric in similarity_matrices.items():\n",
    "        for ds, curr_sim_mat in sim_mats_w_metric.items():\n",
    "            dfs.append(process_sim_mat(curr_sim_mat, sim_metric, ds))\n",
    "    df = pd.concat(dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68e1dee-76a6-4bea-b78a-10a677a9d4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity metric</th>\n",
       "      <th>DS</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Similarity value</th>\n",
       "      <th>Objective pair</th>\n",
       "      <th>Architecture pair</th>\n",
       "      <th>Dataset pair</th>\n",
       "      <th>Model size pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CKA RBF 0.4</td>\n",
       "      <td>wds_fer2013</td>\n",
       "      <td>Kakaobrain_Align</td>\n",
       "      <td>OpenCLIP_EVA01-g-14-plus_merged2b_s11b_b114k</td>\n",
       "      <td>0.468318</td>\n",
       "      <td>(Image-Text, Image-Text)</td>\n",
       "      <td>(Convolutional, Transformer)</td>\n",
       "      <td>(Large DS, XLarge DS)</td>\n",
       "      <td>(small, xlarge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CKA RBF 0.4</td>\n",
       "      <td>wds_fer2013</td>\n",
       "      <td>Kakaobrain_Align</td>\n",
       "      <td>OpenCLIP_EVA01-g-14_laion400m_s11b_b41k</td>\n",
       "      <td>0.419219</td>\n",
       "      <td>(Image-Text, Image-Text)</td>\n",
       "      <td>(Convolutional, Transformer)</td>\n",
       "      <td>(Large DS, Large DS)</td>\n",
       "      <td>(small, xlarge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CKA RBF 0.4</td>\n",
       "      <td>wds_fer2013</td>\n",
       "      <td>Kakaobrain_Align</td>\n",
       "      <td>OpenCLIP_EVA02-B-16_merged2b_s8b_b131k</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>(Image-Text, Image-Text)</td>\n",
       "      <td>(Convolutional, Transformer)</td>\n",
       "      <td>(Large DS, XLarge DS)</td>\n",
       "      <td>(medium, small)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CKA RBF 0.4</td>\n",
       "      <td>wds_fer2013</td>\n",
       "      <td>Kakaobrain_Align</td>\n",
       "      <td>OpenCLIP_EVA02-L-14_merged2b_s4b_b131k</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>(Image-Text, Image-Text)</td>\n",
       "      <td>(Convolutional, Transformer)</td>\n",
       "      <td>(Large DS, XLarge DS)</td>\n",
       "      <td>(small, xlarge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CKA RBF 0.4</td>\n",
       "      <td>wds_fer2013</td>\n",
       "      <td>Kakaobrain_Align</td>\n",
       "      <td>OpenCLIP_RN50_openai</td>\n",
       "      <td>0.518417</td>\n",
       "      <td>(Image-Text, Image-Text)</td>\n",
       "      <td>(Convolutional, Convolutional)</td>\n",
       "      <td>(Large DS, Large DS)</td>\n",
       "      <td>(medium, small)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Similarity metric           DS           Model 1  \\\n",
       "0       CKA RBF 0.4  wds_fer2013  Kakaobrain_Align   \n",
       "1       CKA RBF 0.4  wds_fer2013  Kakaobrain_Align   \n",
       "2       CKA RBF 0.4  wds_fer2013  Kakaobrain_Align   \n",
       "3       CKA RBF 0.4  wds_fer2013  Kakaobrain_Align   \n",
       "4       CKA RBF 0.4  wds_fer2013  Kakaobrain_Align   \n",
       "\n",
       "                                        Model 2  Similarity value  \\\n",
       "0  OpenCLIP_EVA01-g-14-plus_merged2b_s11b_b114k          0.468318   \n",
       "1       OpenCLIP_EVA01-g-14_laion400m_s11b_b41k          0.419219   \n",
       "2        OpenCLIP_EVA02-B-16_merged2b_s8b_b131k          0.485452   \n",
       "3        OpenCLIP_EVA02-L-14_merged2b_s4b_b131k          0.459744   \n",
       "4                          OpenCLIP_RN50_openai          0.518417   \n",
       "\n",
       "             Objective pair               Architecture pair  \\\n",
       "0  (Image-Text, Image-Text)    (Convolutional, Transformer)   \n",
       "1  (Image-Text, Image-Text)    (Convolutional, Transformer)   \n",
       "2  (Image-Text, Image-Text)    (Convolutional, Transformer)   \n",
       "3  (Image-Text, Image-Text)    (Convolutional, Transformer)   \n",
       "4  (Image-Text, Image-Text)  (Convolutional, Convolutional)   \n",
       "\n",
       "            Dataset pair  Model size pair  \n",
       "0  (Large DS, XLarge DS)  (small, xlarge)  \n",
       "1   (Large DS, Large DS)  (small, xlarge)  \n",
       "2  (Large DS, XLarge DS)  (medium, small)  \n",
       "3  (Large DS, XLarge DS)  (small, xlarge)  \n",
       "4   (Large DS, Large DS)  (medium, small)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df = get_similarity_dataframe(sim_mats)\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f699e04f-3e1b-4323-ac9c-cee2182cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.to_csv(storing_path / 'all_metric_ds_model_pair_similarity_with_rsa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
