{
  "dinov2-vit-large-p14": {
    "model_name": "dinov2-vit-large-p14",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "LVD-142M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 1024,
    "alignment": null
  },
  "dinov2-vit-large-p14_gLocal": {
    "model_name": "dinov2-vit-large-p14",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "LVD-142M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 1024,
    "alignment": "gLocal"
  },
  "dino-vit-base-p16": {
    "model_name": "dino-vit-base-p16",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "dino-vit-base-p16_gLocal": {
    "model_name": "dino-vit-base-p16",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": "gLocal"
  },
  "DreamSim_open_clip_vitb32": {
    "model_name": "DreamSim",
    "source": "custom",
    "model_parameters": {
      "variant": "open_clip_vitb32"
    },
    "module_name": "model.mlp",
    "objective": "Image-Text",
    "dataset": "LAION400M + NIGHTS",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 512,
    "alignment": null
  },
  "DreamSim_dino_vitb16": {
    "model_name": "DreamSim",
    "source": "custom",
    "model_parameters": {
      "variant": "dino_vitb16",
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "model.mlp",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k + NIGHTS",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "mae-vit-base-p16": {
    "model_name": "mae-vit-base-p16",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "mae-vit-large-p16": {
    "model_name": "mae-vit-large-p16",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 1024,
    "alignment": null
  },
  "mae-vit-huge-p14": {
    "model_name": "mae-vit-huge-p14",
    "source": "ssl",
    "model_parameters": {
      "extract_cls_token": true,
      "token_extraction": "cls_token"
    },
    "module_name": "norm",
    "objective": "Self-Supervised",
    "dataset": "ImageNet1k",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 1280,
    "alignment": null
  },
  "OpenCLIP_RN50_openai": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "RN50",
      "dataset": "openai"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "WIT-400M",
    "architecture_class": "Transformer",
    "architecture": "ResNet",
    "embedding_dim": 1024,
    "alignment": null
  },
  "OpenCLIP_ViT-B-16_openai": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-B-16",
      "dataset": "openai"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "WIT-400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 512,
    "alignment": null
  },
  "OpenCLIP_ViT-B-16_laion400m_e32": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-B-16",
      "dataset": "laion400m_e32"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 512,
    "alignment": null
  },
  "OpenCLIP_ViT-B-16_laion2b_s34b_b88k": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-B-16",
      "dataset": "laion2b_s34b_b88k"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION2B",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 512,
    "alignment": null
  },
  "OpenCLIP_ViT-L-14_openai": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-L-14",
      "dataset": "openai"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "WIT-400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "OpenCLIP_ViT-L-14_laion400m_e32": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-L-14",
      "dataset": "laion400m_e32"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "OpenCLIP_ViT-L-14_laion400m_e32_gLocal": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-L-14",
      "dataset": "laion400m_e32"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": "gLocal"
  },
  "OpenCLIP_ViT-L-14_laion2b_s32b_b82k": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-L-14",
      "dataset": "laion2b_s32b_b82k"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION2B",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "OpenCLIP_ViT-L-14_laion2b_s32b_b82k_gLocal": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-L-14",
      "dataset": "laion2b_s32b_b82k"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION2B",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": "gLocal"
  },
  "OpenCLIP_ViT-B-16-SigLIP_webli": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "ViT-B-16-SigLIP",
      "dataset": "webli"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "WebLI",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 768,
    "alignment": null
  },
  "OpenCLIP_EVA01-g-14_laion400m_s11b_b41k": {
    "model_name": "OpenCLIP",
    "source": "custom",
    "model_parameters": {
      "variant": "EVA01-g-14",
      "dataset": "laion400m_s11b_b41k"
    },
    "module_name": "visual",
    "objective": "Image-Text",
    "dataset": "LAION400M",
    "architecture_class": "Transformer",
    "architecture": "ViT",
    "embedding_dim": 1024,
    "alignment": null
  }
}
