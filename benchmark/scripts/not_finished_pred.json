{"dinov2-vit-large-p14": {"model_name": "dinov2-vit-large-p14", "source": "ssl", "model_parameters": {"extract_cls_token": true, "token_extraction": "cls_token"}, "module_name": "norm", "objective": "Self-Supervised", "dataset": "LVD-142M", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 1024, "alignment": null}, "dino-vit-base-p16_gLocal": {"model_name": "dino-vit-base-p16", "source": "ssl", "model_parameters": {"extract_cls_token": true, "token_extraction": "cls_token"}, "module_name": "norm", "objective": "Self-Supervised", "dataset": "ImageNet1k", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 768, "alignment": "gLocal"}, "DreamSim_open_clip_vitb32": {"model_name": "DreamSim", "source": "custom", "model_parameters": {"variant": "open_clip_vitb32"}, "module_name": "model.mlp", "objective": "Image-Text", "dataset": "LAION400M + NIGHTS", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 512, "alignment": null}, "DreamSim_dino_vitb16": {"model_name": "DreamSim", "source": "custom", "model_parameters": {"variant": "dino_vitb16", "extract_cls_token": true, "token_extraction": "cls_token"}, "module_name": "model.mlp", "objective": "Self-Supervised", "dataset": "ImageNet1k + NIGHTS", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 768, "alignment": null}, "OpenCLIP_ViT-L-14_laion400m_e32_gLocal": {"model_name": "OpenCLIP", "source": "custom", "model_parameters": {"variant": "ViT-L-14", "dataset": "laion400m_e32"}, "module_name": "visual", "objective": "Image-Text", "dataset": "LAION400M", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 768, "alignment": "gLocal"}, "OpenCLIP_ViT-B-16-SigLIP_webli": {"model_name": "OpenCLIP", "source": "custom", "model_parameters": {"variant": "ViT-B-16-SigLIP", "dataset": "webli"}, "module_name": "visual", "objective": "Image-Text", "dataset": "WebLI", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 768, "alignment": null}, "OpenCLIP_EVA01-g-14_laion400m_s11b_b41k": {"model_name": "OpenCLIP", "source": "custom", "model_parameters": {"variant": "EVA01-g-14", "dataset": "laion400m_s11b_b41k"}, "module_name": "visual", "objective": "Image-Text", "dataset": "LAION400M", "architecture_class": "Transformer", "architecture": "ViT", "embedding_dim": 1024, "alignment": null}}