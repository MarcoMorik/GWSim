{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST run: python create_results_dfs.py [--ensemble] [--datasets ...] <br>\n",
    "This will create the results dataframes in OUTPUT_ROOT (usually: aggregated/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "OUTPUT_ROOT = \"/home/space/diverse_priors/results/aggregated/\"\n",
    "ood_datasets = [\"wds_imagenet-a\", \"wds_imagenet-r\", \"wds_imagenet_sketch\", \"wds_imagenetv2\"]\n",
    "\n",
    "CONFIG_COLS_SINGLE = [\n",
    "    'task',\n",
    "    'mode',\n",
    "    'dataset',\n",
    "    'feature_normalization',\n",
    "    'feature_alignment',\n",
    "    'val_proportion',\n",
    "    'model_ids',\n",
    "    'model_source',\n",
    "    'best_weight_decay'\n",
    "]\n",
    "\n",
    "CONFIG_COLS_MULTIPLE = CONFIG_COLS_SINGLE[:-1] + [\n",
    "    'clustering_method',\n",
    "    'combiner',\n",
    "    'models',\n",
    "    'n_models',\n",
    "    'num_clusters',\n",
    "    'sampling_method',\n",
    "    'similarity_method'\n",
    "]\n",
    "\n",
    "HYPER_PARAMETER_COLS = [\n",
    "    'fewshot_k',\n",
    "    'fewshot_lr',\n",
    "    'fewshot_epochs',\n",
    "    'batch_size'\n",
    "]\n",
    "\n",
    "METRIC_COLS = [\n",
    "    'test_lp_acc1',\n",
    "    'test_lp_acc5',\n",
    "    'test_lp_mean_per_class_recall',\n",
    "]\n",
    "\n",
    "cols_to_display = [\"model_ids\", \"mean\", \"std\"]\n",
    "\n",
    "agg_metric = METRIC_COLS[0]\n",
    "metric_col = 'mean'\n",
    "\n",
    "ds_name_mapping = {\n",
    "    \"wds_imagenet-a\": \"ImageNet-A\",\n",
    "    \"wds_imagenet-r\": \"ImageNet-R\",\n",
    "    \"wds_imagenet_sketch\": \"ImageNet Sketch\",\n",
    "    \"wds_imagenetv2\": \"ImageNet V2\",\n",
    "}\n",
    "\n",
    "sim_metric_name_mapping = {\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.2': 'CKA RBF 0.2',\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.4': 'CKA RBF 0.4',\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.6': 'CKA RBF 0.6',\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.8': 'CKA RBF 0.8',\n",
    "    'cka_kernel_linear_unbiased': 'CKA linear',\n",
    "    'rsa_method_correlation_corr_method_pearson': 'RSA pearson',\n",
    "    'rsa_method_correlation_corr_method_spearman': 'RSA spearman',\n",
    "}\n",
    "\n",
    "model_selec_name_mapping = {\n",
    "    'cluster_best': \"Best model of each cluster\",\n",
    "    'cluster_random': \"Random model of each cluster\",\n",
    "    'top-k': 'Top-k models',\n",
    "    'random': 'Random k models',\n",
    "}\n",
    "\n",
    "base_storing_path = Path('/home/space/diverse_priors/results/plots')\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_or_eval(x):\n",
    "    if x == 'null' or x == '\"null\"':\n",
    "        return None\n",
    "    try:\n",
    "        return eval(x)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def convert_columns(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].apply(null_or_eval)\n",
    "        if isinstance(df[col].iloc[0], list):\n",
    "            df[col] = df[col].apply(lambda x: tuple(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_best_performance_per_config(df, metric, config_cols, ascending=False):\n",
    "    res = df.groupby(config_cols + HYPER_PARAMETER_COLS, dropna=False)[metric].agg(['mean', 'std']).reset_index()\n",
    "    idx = res.reset_index().groupby(config_cols, dropna=False)['mean'].idxmax()\n",
    "    res = res.loc[idx].reset_index(drop=True)\n",
    "    res[f'{metric} mean (std)'] = res.apply(lambda row: f\"{row['mean']:.3f} ({row['std']:.3f})\", axis=1)\n",
    "    res = res.sort_values('mean', ascending=False).reset_index(drop=True)\n",
    "    return res\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_pickle(path)\n",
    "    df = convert_columns(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to apply gradient color\n",
    "def gradient_color(df, metric, vmin=None, vmax=None, dec=3):\n",
    "    return df.style.background_gradient(axis=0,\n",
    "                                        subset=[metric],\n",
    "                                        cmap='coolwarm',\n",
    "                                        vmin=vmin,\n",
    "                                        vmax=vmax).format(precision=dec, subset=[metric])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ood_datasets[a]\n",
    "print(dataset)\n",
    "if SAVE:\n",
    "    storing_path = base_storing_path / dataset\n",
    "    storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(OUTPUT_ROOT, dataset + \"/single_model/results_imagenet1k.pkl\")\n",
    "df = load_data(path)\n",
    "\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_best_performance_per_config(df, agg_metric, CONFIG_COLS_SINGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gradient_color(df[cols_to_display], metric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_single_model_name = 'Best single model'\n",
    "best_single_model = df[0:1].copy()\n",
    "best_single_model['mode'] = best_single_model_name\n",
    "plotting_df = pd.concat([plotting_df, best_single_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T11:35:10.053593Z",
     "start_time": "2024-06-21T11:35:10.049721Z"
    }
   },
   "source": [
    "Single model: Iterating over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ds in ood_datasets:\n",
    "#     path = path = os.path.join(OUTPUT_ROOT, ds+\"/single_model/results_imagenet1k.pkl\")\n",
    "#     df = load_data(path)\n",
    "#     df = get_best_performance_per_config(df, agg_metric, CONFIG_COLS_SINGLE)\n",
    "#     to_display=df[cols_to_display]\n",
    "#     print(ds.upper())\n",
    "#     display(gradient_color(to_display, metric_col) )\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple models: Ensemble & Combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(OUTPUT_ROOT, dataset + \"/ensemble/results_imagenet1k.pkl\")\n",
    "df_en = load_data(path)\n",
    "\n",
    "path = os.path.join(OUTPUT_ROOT, dataset + \"/combined_models/results_imagenet1k.pkl\")\n",
    "df_comb = load_data(path)\n",
    "\n",
    "df = pd.concat([df_en, df_comb])\n",
    "print(df.keys(), df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TnB = df[df.sampling_method.isin(['cluster_best', 'top-k'])].copy()\n",
    "df_R = df[df.sampling_method == 'random'].copy()\n",
    "df_CR = df[df.sampling_method == 'cluster_random'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TnB = get_best_performance_per_config(df_TnB, agg_metric, CONFIG_COLS_MULTIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_random = ['task', 'mode', 'dataset', 'combiner', 'feature_normalization', 'val_proportion', 'sampling_method',\n",
    "                 'n_models']\n",
    "df_R = get_best_performance_per_config(df_R, agg_metric, config_random)\n",
    "\n",
    "config_random += ['similarity_method']\n",
    "df_CR = get_best_performance_per_config(df_CR, agg_metric, config_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_TnB, df_R, df_CR])\n",
    "df.sampling_method.value_counts(), df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = df[metric_col].min()\n",
    "vmax = df[metric_col].max()\n",
    "vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display best performance of Top-K models\n",
    "tmp_df = df[df.sampling_method == 'top-k'][['mode', 'n_models'] + cols_to_display[1:]].sort_values(['mode', 'n_models'])\n",
    "print(\"TOP-K\")\n",
    "gradient_color(tmp_df, metric_col, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Display best performance of best of each cluster selection for different similarity metrics\n",
    "tmp_df = df[df.sampling_method == 'cluster_best'][\n",
    "    ['mode', 'n_models', 'similarity_method'] + cols_to_display[1:]].sort_values(\n",
    "    ['mode', 'n_models', 'similarity_method'])\n",
    "print(\"Best of each cluster\")\n",
    "gradient_color(tmp_df, metric_col, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Display best performance of random model of each cluster selection for different similarity metrics\n",
    "tmp_df = df[df.sampling_method == 'cluster_random'][\n",
    "    ['mode', 'n_models', 'similarity_method'] + cols_to_display[1:]].sort_values(\n",
    "    ['mode', 'n_models', 'similarity_method'])\n",
    "print(\"Random model of each cluster\")\n",
    "gradient_color(tmp_df, metric_col, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display best performance of Random sampling\n",
    "tmp_df = df[df.sampling_method == 'random'][['mode', 'n_models'] + cols_to_display[1:]].sort_values(\n",
    "    ['mode', 'n_models'])\n",
    "print('Random')\n",
    "gradient_color(tmp_df, metric_col, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = df.copy()\n",
    "ensemble['mode'] = ensemble['mode'].map({'ensemble': 'Ensemble', 'combined_models': 'Combined (Concat)'})\n",
    "ensemble['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_df = pd.concat([plotting_df, ensemble])\n",
    "plotting_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined models: Iterating over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ds in ood_datasets:\n",
    "#     path = path = os.path.join(OUTPUT_ROOT, ds+\"/combined_models/results_imagenet1k.pkl\")\n",
    "#     df = pd.read_pickle(path)\n",
    "#     to_display=df[df['test_lp_acc1'] == df['test_lp_acc1'].max()][[\"model_ids\", \"sampling_method\", \"test_lp_acc1\"]]\n",
    "#     display(to_display)\n",
    "#     print(ds, to_display[\"model_ids\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_plot(one_sim_metric, single_row, grouped_data, yvmin, yvmax, metric_col, hue_order):\n",
    "    tab20_colors = sns.color_palette(\"tab20\")\n",
    "    palette = dict(zip(hue_order, tab20_colors[:len(hue_order)]))\n",
    "\n",
    "    # Initialize the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "    # Plot the single row with error bars\n",
    "    ax.bar(single_row['mode'], single_row['mean'], label=f'Best Single model ({single_row[\"mean\"].item():.2f})',\n",
    "           color='#33cccc', capsize=5, width=0.1)\n",
    "    ax.axhline(single_row['mean'].item(), ls=\":\", c='grey', alpha=0.5)\n",
    "\n",
    "    # Plot grouped data with error bars\n",
    "    sns.barplot(\n",
    "        x='n_models',\n",
    "        y=metric_col,\n",
    "        hue='sampling_method_mappend',\n",
    "        hue_order=hue_order,\n",
    "        data=grouped_data,\n",
    "        ax=ax,\n",
    "        palette=palette,\n",
    "        errorbar=None  # Disable the default confidence interval\n",
    "    )\n",
    "\n",
    "    n_diff_ks = np.sort(grouped_data.n_models.unique())\n",
    "\n",
    "    # Manually add error bars for grouped data\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        if i < 1 or i > len(n_diff_ks) * len(hue_order):\n",
    "            continue\n",
    "        n_models = n_diff_ks[(i - 1) % len(n_diff_ks)]\n",
    "        sampling_method = hue_order[(i - 1) // len(n_diff_ks)]\n",
    "\n",
    "        # Get the corresponding std value\n",
    "        subset = grouped_data[(grouped_data['n_models'] == n_models) &\n",
    "                              (grouped_data['sampling_method_mappend'] == sampling_method)]\n",
    "        if subset.shape[0] == 0:\n",
    "            print(n_models, sampling_method)\n",
    "            break\n",
    "        std = subset['std'].values[0]\n",
    "\n",
    "        # Get the bar coordinates\n",
    "        bar_x = bar.get_x() + bar.get_width() / 2\n",
    "        bar_y = bar.get_height()\n",
    "\n",
    "        # Add the error bar\n",
    "        ax.errorbar(bar_x, bar_y, yerr=std, fmt='none', c='black', capsize=5)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_title(f'Performance comparison for {ds_name_mapping[dataset]} ({sim_metric_name_mapping[one_sim_metric]})')\n",
    "    ax.set_ylabel('Mean Top-1 Test Accuracy')\n",
    "    ax.set_xlabel('Nr. of models')\n",
    "    ax.legend(title='Model selection method', framealpha=1, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    ax.set_ylim([ylim_min, ylim_max])\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hue_order = [\n",
    "#     'Ensemble: Top-k models',\n",
    "#     'Ensemble: Best model of each cluster', \n",
    "#     'Ensemble: Random model of each cluster',\n",
    "#     'Ensemble: Random k models', \n",
    "#     'Combined (Concat): Top-k models',\n",
    "#     'Combined (Concat): Best model of each cluster',\n",
    "#     'Combined (Concat): Random model of each cluster',\n",
    "#     'Combined (Concat): Random k models',\n",
    "#     ]\n",
    "\n",
    "hue_order = [\n",
    "    'Ensemble: Top-k models',\n",
    "    'Combined (Concat): Top-k models',\n",
    "    'Ensemble: Best model of each cluster',\n",
    "    'Combined (Concat): Best model of each cluster',\n",
    "    'Ensemble: Random model of each cluster',\n",
    "    'Combined (Concat): Random model of each cluster',\n",
    "    'Ensemble: Random k models',\n",
    "    'Combined (Concat): Random k models',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim_metric in sim_metric_name_mapping.keys():\n",
    "    curr_plotting_df = plotting_df[plotting_df.similarity_method.isin([sim_metric, np.nan])].copy()\n",
    "    curr_plotting_df.similarity_method.value_counts(dropna=False)\n",
    "    ylim_min = curr_plotting_df[metric_col].min() - 0.1\n",
    "    ylim_max = curr_plotting_df[metric_col].max() + 0.02\n",
    "\n",
    "    single_row = curr_plotting_df[curr_plotting_df['mode'] == best_single_model_name].copy()\n",
    "    grouped_data = curr_plotting_df[curr_plotting_df['mode'] != best_single_model_name].copy()\n",
    "    grouped_data['sampling_method_mappend'] = grouped_data.apply(\n",
    "        lambda x: f\"{x['mode']}: {model_selec_name_mapping[x['sampling_method']]}\", axis=1)\n",
    "\n",
    "    # # TODO: Remove if combined models have also cluster_random. \n",
    "    # tmp = grouped_data[(grouped_data['sampling_method_mappend']=='Combined (Concat): Random model of each cluster')&\\\n",
    "    # (grouped_data['n_models']==4)].copy()\n",
    "    # for n in [3, 6, 7]:\n",
    "    #     tmp.loc[:,'n_models'] = n\n",
    "    #     grouped_data = pd.concat([grouped_data, tmp.copy()])\n",
    "    # grouped_data = grouped_data.reset_index()\n",
    "\n",
    "    fig = create_bar_plot(sim_metric, single_row, grouped_data, ylim_min, ylim_max, metric_col, hue_order)\n",
    "\n",
    "    # # if SAVE:\n",
    "    # #     plt.savefig(storing_path / f'comparison_models_{dataset}_{sim_metric}.pdf', bbox_inches='tight')\n",
    "    # #     plt.savefig(storing_path / f'comparison_models_{dataset}_{sim_metric}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
